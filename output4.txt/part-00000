scala,28
nomenclature,1
javasparkcontextconf,1
flatmaptopair,1
saved,1
event,1
sort,4
caching,3
outside,3
linelengthspersiststoragelevelmemoryonly,1
full,4
sparksubmit,5
pairings,1
repartitioning,1
order,4
type,15
add,13
through,11
period,1
javasparkcontextnewapihadooprdd,1
corresponding,1
over,2
networkmounted,1
iterablev,2
implementation,1
orgapachespark,1
select,1
make,3
task,5
contract,1
rdds,20
these,16
initialvalue,1
consequently,1
zip,1
leftouterjoin,1
are,47
optional,4
consists,1
times,1
scalawrite,2
given,6
countreturn,1
necessarily,1
our,1
allocations,1
consisting,1
fx,1
anonymous,2
larger,2
design,1
relate,1
final,4
addition,4
pairs,24
per,2
during,3
countscollect,1
shared,9
long,2
unnecessary,1
small,2
rightouterjoin,1
associated,1
persisting,2
evaluation,1
rather,4
while,6
at,6
below,7
object,4
url,2
class,12
shows,3
new,17
sparkcore,1
concurrently,1
directly,1
transferring,1
broadcasted,1
sparkconfsetappnameappnamesetmastermaster,1
four,1
may,12
except,1
mllib,1
allows,4
broadcastvar,1
find,1
command,1
or,53
interpreteraware,1
filter,2
objecthashcode,1
fields,1
referenced,2
wanted,1
slength,3
of,170
ordered,3
mathematical,1
configuration,4
sctextfiledatatxt,5
often,2
functions,15
function,19
working,2
modified,1
inner,2
num,2
write,2
collectreturn,1
foreachx,1
faulttolerant,2
results,3
remote,2
iteratoru,2
generates,3
orgapachesparkapijavajavasparkcontext,1
sortbykeyascending,1
concisely,2
describe,2
arraysaslist,1
here,5
aware,1
otherwise,3
partitioned,1
first,9
uri,2
for,83
needed,5
already,1
collecting,1
parallelism,1
cost,1
property,1
syntax,2
updating,2
sequencefilek,1
enables,1
example,21
textfilemydirectory,1
x,3
extends,1
seed,2
popular,1
operated,4
generator,2
mapfuncreturn,1
strings,1
tostring,1
references,1
please,1
returning,2
cores,1
machine,8
r,5
create,14
builtin,1
fault,2
unionotherdatasetreturn,1
closure,6
runs,4
number,13
classes,6
simply,2
might,2
higher,2
preserved,1
specialized,1
occurs,1
operator,1
offheap,4
reduces,2
wont,1
update,4
perl,1
fragment,1
define,2
accumulate,1
other,12
join,3
passes,1
linesmaps,1
outofthebox,1
executes,1
custom,3
attempting,1
replicate,2
coalescenumpartitionsdecrease,1
getlength,2
wrapper,1
note,10
name,3
hashcode,1
binpyspark,1
intersection,1
jobconf,1
countbykeyonly,1
u,3
future,2
finally,6
,269
globally,1
migrating,2
child,1
maptodouble,1
drops,1
mutations,1
items,1
changes,1
experimentalstore,1
default,8
furthermore,1
wildcards,1
consume,2
next,1
its,12
allow,1
writing,3
recompute,1
have,5
computation,2
added,4
leave,1
such,8
formed,2
accumulable,1
components,1
rddtakeforeachprintln,1
abstraction,2
common,7
workers,1
happens,1
losing,1
testing,4
storage,14
marked,2
hand,1
immediately,1
transformations,10
called,11
the,377
includes,2
comfortably,1
applied,3
aggregating,1
intwritable,1
if,29
build,2
attractive,1
heap,2
serializer,1
computes,2
eg,10
intended,1
written,3
apis,1
computed,8
multiple,6
heavily,1
fewer,2
lineage,1
iterative,1
though,1
dependencies,2
together,3
efficient,5
mb,1
better,1
optimizing,1
operation,13
programming,2
sizes,1
array,6
repositories,2
unwieldy,1
lru,1
listvalue,1
text,9
tolerance,1
would,5
javardds,1
sure,3
map,16
outlined,1
keys,3
subclasses,1
shuffles,1
addinplace,1
lost,4
script,4
similar,2
behave,2
due,1
efficiency,1
use,25
jvm,4
ui,2
distdata,2
serve,1
files,10
effects,1
costly,1
executor,5
master,9
amazon,1
available,8
code,13
backward,1
more,17
temporary,1
friendly,1
tuning,1
ensure,2
generate,2
numpartitions,1
making,4
inefficient,1
supports,6
counting,1
orgapachesparksparkconf,1
occur,1
accumulatorparamvector,1
compute,3
hadoopclient,2
numtasks,1
job,2
themselves,1
ordering,2
avoid,1
sonatype,1
locally,1
changed,1
only,15
still,5
normally,2
documentation,2
which,24
although,2
should,9
conversions,1
copied,2
conciseness,1
ascending,2
recomputed,4
much,5
jars,3
combop,1
sums,2
base,2
can,52
expensive,2
executing,2
nodes,11
pre,2
sets,1
persisted,2
sufficiently,1
intermediate,2
off,1
by,38
compatibility,1
path,4
separated,1
both,2
an,62
vectorzerosinitialvaluesize,1
alphabetically,1
passed,2
driver,23
counter,10
sn,1
older,1
sparkcontextstop,1
repartitionandsortwithinpartitions,1
javasparkcontexts,1
around,3
with,31
global,2
orgexampleexample,1
foreachfuncrun,1
firstreturn,1
takeorderedn,1
versions,5
significantly,1
configuring,1
try,1
counters,2
expected,2
naive,1
javasparkcontext,2
depending,1
understanding,5
stdin,1
textfilemydirectorygz,1
options,1
sparkconf,2
share,2
displayed,1
commaseparated,2
bash,1
every,2
cycle,1
vectoraccumulatorparam,2
cannot,2
describes,2
copies,3
import,4
their,6
above,3
appname,1
distfile,2
propagated,1
javarddstring,5
performed,1
another,1
manager,1
totallength,3
format,5
actions,9
packages,3
list,5
web,1
important,4
providing,1
slices,1
shuffled,1
io,3
were,3
approach,1
mapped,2
transformed,1
variety,1
acted,2
rddunpersist,1
distdatareducea,1
zerovector,1
guarantee,1
repartition,3
executed,4
programmers,2
